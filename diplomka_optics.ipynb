{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import OPTICS\n",
    "import os\n",
    "import math\n",
    "from itertools import compress\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def get_dominant_parent_cluster(child_id, generation, population_df, crossover_df, cluster_map_prev_gen, pop_data):\n",
    "    \"\"\"\n",
    "    Urƒç√≠ dominantn√≠ rodiƒçovsk√Ω cluster pro dan√©ho potomka podle bli≈æ≈°√≠ho rodiƒçe.\n",
    "    Pokud je jedinec elitou (p≈ôenesen z p≈ôedchoz√≠ generace), ≈æ√°dn√Ω cluster nevrac√≠.\n",
    "    \"\"\"\n",
    "    \n",
    "    # P≈ôiprav slovn√≠k: ID jedinc≈Ø v p≈ôedchoz√≠ generaci ‚Üí vektory\n",
    "    pop_data_prev = {\n",
    "        row[\"id\"]: row.drop([\"id\", \"generation\"]).values\n",
    "        for _, row in population_df[population_df[\"generation\"] == generation - 1].iterrows()\n",
    "    }\n",
    "\n",
    "    # Najdi glob√°ln√≠ ID potomka v t√©to generaci\n",
    "    child_row = population_df[population_df[\"generation\"] == generation].iloc[child_id]\n",
    "    child_global_id = child_row[\"id\"]\n",
    "\n",
    "    # Pokud u≈æ existoval v p≈ôedchoz√≠ generaci ‚Üí jedn√° se o elitu\n",
    "    if child_global_id in pop_data_prev:\n",
    "        # Zjist√≠me jeho p≈Øvodn√≠ cluster z p≈ôedchoz√≠ generace\n",
    "        for cluster_id, members in cluster_map_prev_gen.items():\n",
    "            if child_global_id in members:\n",
    "                #print(f\"[{generation}] Elitn√≠ jedinec ID {child_global_id} ‚Üí zachov√°n v clusteru {cluster_id}\")\n",
    "                return cluster_id\n",
    "        #print(f\"[{generation}] Elitn√≠ jedinec ID {child_global_id} ‚Üí nebyl nalezen v ≈æ√°dn√©m clusteru (chyba?)\")\n",
    "        return None\n",
    "\n",
    "    # Najdi rodiƒçe potomka\n",
    "    crossover_row = crossover_df[\n",
    "        (crossover_df[\"Child1\"] == child_global_id) | (crossover_df[\"Child2\"] == child_global_id)\n",
    "    ]\n",
    "    if crossover_row.empty:\n",
    "        #print(f\"[{generation}] Child ID {child_global_id} ‚Üí rodiƒçe nebyli nalezeni.\")\n",
    "        return None\n",
    "\n",
    "    parent1 = crossover_row.iloc[0][\"Parent1\"]\n",
    "    parent2 = crossover_row.iloc[0][\"Parent2\"]\n",
    "\n",
    "    # Najdi clustery rodiƒç≈Ø\n",
    "    parent1_cluster = next((cid for cid, members in cluster_map_prev_gen.items() if parent1 in members), None)\n",
    "    parent2_cluster = next((cid for cid, members in cluster_map_prev_gen.items() if parent2 in members), None)\n",
    "\n",
    "    # Vektory\n",
    "    child_vector = pop_data[child_id]\n",
    "    parent1_vector = pop_data_prev.get(parent1, None)\n",
    "    parent2_vector = pop_data_prev.get(parent2, None)\n",
    "\n",
    "    selected_cluster = None\n",
    "    selected_parent = None\n",
    "\n",
    "    # Rozhodni podle bli≈æ≈°√≠ho rodiƒçe\n",
    "    if parent1_cluster is not None and parent2_cluster is not None and parent1_vector is not None and parent2_vector is not None:\n",
    "        d1 = np.linalg.norm(child_vector - parent1_vector)\n",
    "        d2 = np.linalg.norm(child_vector - parent2_vector)\n",
    "        selected_cluster = parent1_cluster if d1 <= d2 else parent2_cluster\n",
    "        selected_parent = parent1 if d1 <= d2 else parent2\n",
    "    elif parent1_cluster is not None:\n",
    "        selected_cluster = parent1_cluster\n",
    "        selected_parent = parent1\n",
    "    elif parent2_cluster is not None:\n",
    "        selected_cluster = parent2_cluster\n",
    "        selected_parent = parent2\n",
    "\n",
    "    #print(f\"[{generation}] Child ID {child_global_id} ‚Üí Parent1: {parent1}, Parent2: {parent2}, Selected parent: {selected_parent}, Cluster: {selected_cluster}\")\n",
    "\n",
    "    return selected_cluster\n",
    "\n",
    "def schwefel(coordinates):\n",
    "    result = 0\n",
    "    for coordinate in coordinates:\n",
    "        result += coordinate * math.sin(math.sqrt(abs(coordinate)))\n",
    "    return 418.9829 * len(coordinates) - result\n",
    "\n",
    "def sphere(x):\n",
    "    return sum([xi**2 for xi in x])\n",
    "\n",
    "def map_and_remap_clusters(\n",
    "    gen_index,\n",
    "    prev_clusters_members, curr_clusters_members,\n",
    "    clusters_array, pop_data,\n",
    "    global_id_counter,\n",
    "    use_jaccard=True,\n",
    "    pop_data_df=None,\n",
    "    crossover_data_df=None\n",
    "):\n",
    "    if gen_index > 0 and global_id_counter == 0:\n",
    "        global_id_counter = max(prev_clusters_members.keys()) + 1\n",
    "\n",
    "    if gen_index == 0:\n",
    "        new_ids = {}\n",
    "        for cid in curr_clusters_members.keys():\n",
    "            new_ids[cid] = global_id_counter\n",
    "            global_id_counter += 1\n",
    "\n",
    "        new_clusters_array = np.array([\n",
    "            new_ids[cl] if cl in new_ids else -1 for cl in clusters_array\n",
    "        ])\n",
    "        new_centroids = np.array([\n",
    "            np.mean(pop_data[np.array(new_clusters_array) == gid], axis=0)\n",
    "            for gid in sorted(new_ids.values())\n",
    "        ])\n",
    "        new_cluster_members = {\n",
    "            new_ids[cid]: members for cid, members in curr_clusters_members.items()\n",
    "        }\n",
    "\n",
    "        return new_clusters_array, new_centroids, new_cluster_members, global_id_counter\n",
    "\n",
    "    suggestions = defaultdict(list)\n",
    "    id_mapping = {}\n",
    "    if not use_jaccard:\n",
    "        # === 1. Dominantn√≠ historick√Ω cluster pro ka≈æd√Ω jedinec ===\n",
    "        previous_ids = {}\n",
    "        for ident, cluster in zip(range(len(clusters_array)), clusters_array):\n",
    "            if cluster == -1:\n",
    "                continue\n",
    "            dominant_parent_cluster = get_dominant_parent_cluster(\n",
    "                child_id=ident,\n",
    "                generation=gen_index,\n",
    "                population_df=pop_data_df,\n",
    "                crossover_df=crossover_data_df,\n",
    "                cluster_map_prev_gen=prev_clusters_members,\n",
    "                pop_data=pop_data\n",
    "            )\n",
    "            if dominant_parent_cluster is not None:\n",
    "                previous_ids[ident] = dominant_parent_cluster\n",
    "\n",
    "        # === 2. Shluky ‚Üí historick√© ID ƒçlen≈Ø\n",
    "        cluster_to_past_ids = defaultdict(list)\n",
    "        for ident, cluster in zip(range(len(clusters_array)), clusters_array):\n",
    "            if cluster == -1 or ident not in previous_ids:\n",
    "                continue\n",
    "            cluster_to_past_ids[cluster].append(previous_ids[ident])\n",
    "\n",
    "        # === 3. Sb√≠r√°n√≠ n√°vrh≈Ø od v≈°ech cluster≈Ø ===\n",
    "        cluster_votes = []\n",
    "        for curr_cluster_id, past_ids in cluster_to_past_ids.items():\n",
    "            #print(f\"[GEN {gen_index}] Cluster {curr_cluster_id} obsahuje:\")\n",
    "            counter = Counter(past_ids)\n",
    "            #for cid, count in counter.items():\n",
    "                #print(f\"   - {count}x historick√Ω cluster {cid} (velikost v minulosti: {len(prev_clusters_members.get(cid, []))})\")\n",
    "\n",
    "            if not past_ids:\n",
    "                continue\n",
    "\n",
    "            top = counter.most_common()\n",
    "            max_count = top[0][1]\n",
    "            top_candidates = [cid for cid, cnt in top if cnt == max_count]\n",
    "\n",
    "            best_candidate = max(\n",
    "                top_candidates,\n",
    "                key=lambda cid: len(prev_clusters_members.get(cid, set()))\n",
    "            )\n",
    "\n",
    "            cluster_votes.append((curr_cluster_id, best_candidate, counter[best_candidate], len(curr_clusters_members[curr_cluster_id])))\n",
    "\n",
    "        # === 4. ≈òe≈°en√≠ koliz√≠ ===\n",
    "        #id_mapping = {}\n",
    "        used_prev_ids = set()\n",
    "\n",
    "        # Pro ka≈æd√Ω historick√Ω cluster zjist√≠me, kdo o nƒõj ≈æ√°d√°\n",
    "        requests = defaultdict(list)\n",
    "        for cluster_id, wanted_id, votes, size in cluster_votes:\n",
    "            requests[wanted_id].append((cluster_id, votes, size))\n",
    "\n",
    "        for wanted_id, contenders in requests.items():\n",
    "            if len(contenders) == 1:\n",
    "                # jedin√Ω z√°jemce\n",
    "                cluster_id, _, _ = contenders[0]\n",
    "                id_mapping[cluster_id] = wanted_id\n",
    "                used_prev_ids.add(wanted_id)\n",
    "                #print(f\"   ‚Üí P≈ôi≈ôazen historick√Ω cluster {wanted_id} (≈æ√°dn√Ω soupe≈ô)\")\n",
    "            else:\n",
    "                # kolize: rozhodni podle poƒçtu hlas≈Ø, pak podle velikosti\n",
    "                contenders.sort(key=lambda x: (-x[1], -x[2]))  # prim√°rnƒõ hlas≈Ø, sekund√°rnƒõ velikost\n",
    "                winner_id, _, _ = contenders[0]\n",
    "                id_mapping[winner_id] = wanted_id\n",
    "                used_prev_ids.add(wanted_id)\n",
    "                #print(f\"   ‚Üí P≈ôi≈ôazen historick√Ω cluster {wanted_id} clusteru {winner_id} (vyhr√°l v konkurenci)\")\n",
    "                #for cluster_id, _, _ in contenders[1:]:\n",
    "                #    print(f\"   ‚Üí Cluster {cluster_id} prohr√°l spor o historick√Ω cluster {wanted_id}\")\n",
    "\n",
    "        # === 5. Zbytek nov√Ωch cluster≈Ø dostane nov√© ID\n",
    "        for cid in curr_clusters_members:\n",
    "            if cid not in id_mapping:\n",
    "                id_mapping[cid] = global_id_counter\n",
    "                #print(f\"üÜï Cluster {cid} nedostal ≈æ√°dn√© historick√© ID ‚Üí nov√© ID {global_id_counter}\")\n",
    "                global_id_counter += 1\n",
    "    else:\n",
    "\n",
    "        # === 1. Ka≈æd√Ω star√Ω cluster navrhne JEDEN nejlep≈°√≠ nov√Ω cluster ===\n",
    "        #suggestions = defaultdict(list)\n",
    "\n",
    "        for prev_id, prev_members in prev_clusters_members.items():\n",
    "            best_score = -1\n",
    "            best_curr_id = None\n",
    "            for curr_id, curr_members in curr_clusters_members.items():\n",
    "                intersection = len(prev_members & curr_members)\n",
    "                union = len(prev_members | curr_members)\n",
    "                if union == 0:\n",
    "                    continue\n",
    "                jaccard = intersection / union\n",
    "                if jaccard > best_score:\n",
    "                    best_score = jaccard\n",
    "                    best_curr_id = curr_id\n",
    "            if best_curr_id is not None:\n",
    "                suggestions[best_curr_id].append((prev_id, best_score)) \n",
    "\n",
    "        # === Debug v√Ωpis n√°vrh≈Ø ===\n",
    "        #print(\"\\n--- N√°vrhy pro nov√© clustery (p≈ôesnƒõ jeden od ka≈æd√©ho p≈ôedka) ---\")\n",
    "        #for curr_id, proposals in suggestions.items():\n",
    "            #print(f\"Nov√Ω cluster {curr_id}: {[f'{pid} ({score:.2f})' for pid, score in sorted(proposals, key=lambda x: -x[1])]}\")\n",
    "        #print(f\"[GEN {gen_index}] Jaccard mapping n√°vrhy:\")\n",
    "        #for curr_id, proposals in suggestions.items():\n",
    "        #    print(f\"  Nov√Ω cluster {curr_id} ‚Üí {[f'prev {pid} ({score:.2f})' for pid, score in proposals]}\")\n",
    "\n",
    "\n",
    "        # === 2. V√Ωbƒõr nejlep≈°√≠ho nepou≈æit√©ho p≈ôedka\n",
    "        used_prev_ids = set()\n",
    "        #id_mapping = {}\n",
    "        for curr_id, proposals in suggestions.items():\n",
    "            proposals.sort(key=lambda x: -x[1])  # podle Jaccarda sestupnƒõ\n",
    "            for prev_id, score in proposals:\n",
    "                if prev_id not in used_prev_ids:\n",
    "                    id_mapping[curr_id] = prev_id\n",
    "                    used_prev_ids.add(prev_id)\n",
    "                    #print(f\"‚úîÔ∏è Cluster {curr_id} byl namapov√°n na {prev_id} (Jaccard: {score:.2f})\")\n",
    "                    break\n",
    "\n",
    "        # === 3. Zbytek nov√Ωch cluster≈Ø dostane nov√© ID\n",
    "        for curr_id in curr_clusters_members:\n",
    "            if curr_id not in id_mapping:\n",
    "                id_mapping[curr_id] = global_id_counter\n",
    "                #print(f\"üÜï Cluster {curr_id} nedostal ≈æ√°dn√©ho p≈ôedka ‚Äì p≈ôidƒõleno nov√© ID: {global_id_counter}\")\n",
    "                global_id_counter += 1\n",
    "    \n",
    "    # === 4. Mapov√°n√≠ pole cluster≈Ø\n",
    "    new_clusters_array = np.array([\n",
    "        id_mapping[cl] if cl in id_mapping else -1 for cl in clusters_array\n",
    "    ])\n",
    "\n",
    "    # === 5. P≈ôepoƒçet centroid≈Ø\n",
    "    new_centroids = []\n",
    "    new_cluster_ids = sorted(set(id_mapping.values()))\n",
    "    for gid in new_cluster_ids:\n",
    "        member_data = pop_data[np.array(new_clusters_array) == gid]\n",
    "        if len(member_data) > 0:\n",
    "            new_centroids.append(np.mean(member_data, axis=0))\n",
    "    new_centroids = np.array(new_centroids)\n",
    "\n",
    "    # === 6. ƒålenov√© cluster≈Ø podle nov√©ho mapov√°n√≠\n",
    "    new_cluster_members = {}\n",
    "    for curr_id, members in curr_clusters_members.items():\n",
    "        gid = id_mapping[curr_id]\n",
    "        new_cluster_members[gid] = members\n",
    "\n",
    "    return new_clusters_array, new_centroids, new_cluster_members, global_id_counter\n",
    "\n",
    "\n",
    "def compute_inertia(data, labels, centroids):\n",
    "    inertia = 0.0\n",
    "    for i, point in enumerate(data):\n",
    "        label = labels[i]\n",
    "        if label == -1:\n",
    "            continue  # noise ignoruj\n",
    "        inertia += np.sum((point - centroids[label]) ** 2)\n",
    "    return inertia\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def run(dataset, min_samples, step, fintess_method, clustering_method_name, evol_name, crossover=None):\n",
    "    output_dir = os.path.join(\"html_report\", evol_name, fintess_method.__name__, clustering_method_name)\n",
    "    images_dir = os.path.join(output_dir, \"images\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "    html_parts = [\n",
    "        \"<html><head><meta charset='utf-8'><title>Optics clustering Report</title></head><body>\",\n",
    "        \"<h1>Optics shlukov√°n√≠ ‚Äì V√Ωvoj</h1>\"\n",
    "    ]\n",
    "    centroid_history = []\n",
    "    df = pd.read_csv(dataset)\n",
    "    crossover_df = None\n",
    "    if evol_name == \"GA\":\n",
    "        crossover_df = pd.read_csv(crossover)\n",
    "\n",
    "    unique_generations = sorted(df[\"generation\"].unique())\n",
    "\n",
    "    #selected_generations = [unique_generations[0]] + unique_generations[step-1::step] + [unique_generations[-1]]\n",
    "    selected_generations = list(dict.fromkeys(\n",
    "        [unique_generations[0]] + unique_generations[step-1::step] + [unique_generations[-1]]\n",
    "    ))\n",
    "\n",
    "    first_gen_data = df[df[\"generation\"] == unique_generations[0]].drop(columns=[\"generation\", \"id\"]).values\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(first_gen_data)\n",
    "    id_cluster_map = defaultdict(list)\n",
    "    cluster_counts = []\n",
    "    cluster_size_history = []\n",
    "    inertia_history = []\n",
    "    cluster_members_by_gen = {}\n",
    "    #global_cluster_map = {}  # {generation: {local_cluster_id: global_id}}\n",
    "    global_id_counter = 0\n",
    "\n",
    "\n",
    "    #for gen in selected_generations:\n",
    "    for gen_ind, gen in enumerate(selected_generations):\n",
    "\n",
    "        pop_data = df[df[\"generation\"] == gen].drop(columns=[\"generation\", \"id\"]).values\n",
    "        reduced_data = pca.transform(pop_data)\n",
    "\n",
    "        max_distance = np.max(cdist(pop_data, pop_data))\n",
    "        eps = 0.35 * max_distance\n",
    "        #print(0.5 * max_distance)\n",
    "        #print(0.25 * max_distance)\n",
    "        #print(0.05 * max_distance)\n",
    "\n",
    "        #print(pop_data)\n",
    "\n",
    "        #clusters = custom_optics_clustering(data=pop_data, min_samples=min_samples, max_eps=eps, eps=None)\n",
    "        #print(clusters)\n",
    "        clustering = None\n",
    "        percent_outliers = None\n",
    "        for epx_mult in np.arange(0.05, 0.5, 0.05):\n",
    "            for xi_value in np.arange(0.01, 0.20, 0.01):\n",
    "                clustering = OPTICS(\n",
    "                    min_samples=min_samples,      # Minim√°ln√≠ poƒçet bod≈Ø v hust√© oblasti\n",
    "                    max_eps=epx_mult*max_distance,     # Maxim√°ln√≠ hledan√Ω radius (np.inf = automaticky)\n",
    "                    xi=xi_value,           # Parametr pro automatickou extrakci shluk≈Ø (voliteln√©)\n",
    "                    metric='euclidean' # Vzd√°lenostn√≠ metrika\n",
    "                )\n",
    "\n",
    "                # Fitov√°n√≠ modelu\n",
    "                clustering.fit(pop_data)\n",
    "                num_outliers = np.sum(clustering.labels_ == -1)\n",
    "                percent_outliers = num_outliers / len(pop_data) * 100\n",
    "                if(percent_outliers < 50):\n",
    "                    #print(\"break \"+ str(epx_mult) + \" \" + str(xi_value))\n",
    "                    break\n",
    "            if(percent_outliers < 50):\n",
    "                break\n",
    "\n",
    "\n",
    "        # V√Ωsledn√© labely (-1 = outlier)\n",
    "        clusters = clustering.labels_\n",
    "\n",
    "        centroids = []\n",
    "        for i in range(min(clusters), max(clusters)+1):\n",
    "            if i == -1:\n",
    "                continue\n",
    "            members = pop_data[clusters == i]\n",
    "            if len(members) > 0:\n",
    "                centroid = np.mean(members, axis=0)\n",
    "                centroids.append(centroid)\n",
    "        centroid_history.append(centroids)\n",
    "        inertia = compute_inertia(pop_data, clusters, centroids)\n",
    "        inertia_history.append(inertia)\n",
    "\n",
    "\n",
    "\n",
    "        num_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "        cluster_counts.append(num_clusters)\n",
    "        ids = df[df[\"generation\"] == gen][\"id\"].values\n",
    "        #for ident, cl in zip(ids, clusters):\n",
    "        #    id_cluster_map[ident].append(cl)\n",
    "        sizes = []\n",
    "        for i in range(-1, max(clusters)+1):\n",
    "            sizes.append(np.sum(clusters == i))\n",
    "        cluster_size_history.append(sizes)\n",
    "\n",
    "        # === Ulo≈æen√≠ ƒçlen≈Ø cluster≈Ø pro aktu√°ln√≠ generaci ===\n",
    "        #cluster_to_ids = defaultdict(set)\n",
    "        #for ident, cl in zip(ids, clusters):\n",
    "        #    cluster_to_ids[cl].add(ident)\n",
    "        #cluster_members_by_gen[gen] = cluster_to_ids\n",
    "\n",
    "        # === P≈ôemapov√°n√≠ cluster≈Ø pomoc√≠ Jaccard (bez glob√°ln√≠ mapy)\n",
    "        prev_clusters_members = cluster_members_by_gen[selected_generations[gen_ind - 1]] if gen_ind > 0 else None\n",
    "        curr_clusters_members = defaultdict(set)\n",
    "        for ident, cl in zip(ids, clusters):\n",
    "            if cl != -1:\n",
    "                curr_clusters_members[cl].add(ident)\n",
    "\n",
    "        if evol_name != \"GA\":\n",
    "            if prev_clusters_members is not None:\n",
    "                clusters, centroids, curr_clusters_members, global_id_counter = map_and_remap_clusters(\n",
    "                    gen_ind,\n",
    "                    prev_clusters_members,\n",
    "                    curr_clusters_members,\n",
    "                    clusters,\n",
    "                    pop_data,\n",
    "                    global_id_counter,\n",
    "                    True\n",
    "                )\n",
    "        else:\n",
    "            if prev_clusters_members is not None:\n",
    "                clusters, centroids, curr_clusters_members, global_id_counter = map_and_remap_clusters(\n",
    "                    gen_ind,\n",
    "                    prev_clusters_members,\n",
    "                    curr_clusters_members,\n",
    "                    clusters,\n",
    "                    pop_data,\n",
    "                    global_id_counter,\n",
    "                    False,\n",
    "                    df,\n",
    "                    crossover_df\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "        cluster_members_by_gen[gen] = curr_clusters_members\n",
    "\n",
    "        # === A≈æ teƒè ulo≈æ√≠me do `id_cluster_map`\n",
    "        for ident, cl in zip(ids, clusters):\n",
    "            id_cluster_map[ident].append(cl)\n",
    "\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        scatter = plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=clusters, cmap='viridis', alpha=0.7)\n",
    "\n",
    "        handles, _ = scatter.legend_elements(prop=\"colors\")\n",
    "        legend_labels = [f\"Shluk {cl}\" for cl in sorted(set(clusters))]  # ‚Üê re√°ln√© n√°zvy\n",
    "\n",
    "        plt.legend(handles, legend_labels, title=\"Shluky\", loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "                ncol=5, fontsize=8, frameon=False)\n",
    "        plt.title(f\"Generace {gen} - Optics Shlukov√°n√≠\")\n",
    "        plt.xlabel(\"PCA komponent 1\")\n",
    "        plt.ylabel(\"PCA komponent 2\")\n",
    "        plt.tight_layout()\n",
    "        scatter_path = os.path.join(images_dir, f\"scatter_gen_{gen:03d}.png\")\n",
    "        plt.savefig(scatter_path)\n",
    "        plt.close()\n",
    "\n",
    "        html_parts.append(f\"<h2>Generace {gen}</h2>\")\n",
    "        html_parts.append(f\"<img src='images/{os.path.basename(scatter_path)}' width='600'><br>\")\n",
    "\n",
    "\n",
    "        # === Histogram velikost√≠ cluster≈Ø (distribuce) ===\n",
    "        #unique_labels = sorted(set(clusters))\n",
    "        #cluster_sizes = [np.sum(clusters == label) for label in unique_labels]\n",
    "        #plt.figure(figsize=(6, 4))\n",
    "        #bars = plt.bar(unique_labels, cluster_sizes, color='skyblue', edgecolor='black')\n",
    "        #plt.xticks([])\n",
    "        #for bar, label in zip(bars, unique_labels):\n",
    "        #    height = bar.get_height()\n",
    "        #    if height > 0:\n",
    "        #        plt.text(bar.get_x() + bar.get_width() / 2.0,\n",
    "        #                -0.5,\n",
    "        #                f\"Shluk {label}\",\n",
    "        #                ha='center', va='top', rotation=90, fontsize=8)\n",
    "        #\n",
    "        #plt.ylabel(\"Poƒçet jedinc≈Ø\")\n",
    "        #plt.title(f\"Histogram velikost√≠ shluk≈Ø - generace {gen}\")\n",
    "        #plt.grid(True, axis='y')\n",
    "        #plt.tight_layout()\n",
    "        #hist_path = os.path.join(images_dir, f\"histogram_gen_{gen:03d}.png\")\n",
    "        #plt.savefig(hist_path)\n",
    "        #plt.close()\n",
    "        #html_parts.append(f\"<img src='images/{os.path.basename(hist_path)}' width='600'><br>\")\n",
    "        # Z√≠sk√°n√≠ unik√°tn√≠ch label≈Ø a jejich velikost√≠\n",
    "        # Z√≠sk√°n√≠ unik√°tn√≠ch label≈Ø a jejich velikost√≠\n",
    "        unique_labels = sorted(set(clusters))\n",
    "        cluster_sizes = [np.sum(clusters == label) for label in unique_labels]\n",
    "\n",
    "        # Filtrov√°n√≠ jen nepr√°zdn√Ωch shluk≈Ø\n",
    "        filtered = [(label, size) for label, size in zip(unique_labels, cluster_sizes) if size > 0]\n",
    "        if not filtered:\n",
    "            filtered_labels, filtered_sizes = [], []\n",
    "        else:\n",
    "            filtered_labels, filtered_sizes = zip(*filtered)\n",
    "\n",
    "        # Vykreslen√≠ histogramu s indexy m√≠sto skuteƒçn√Ωch label≈Ø jako sou≈ôadnic\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        x_pos = range(len(filtered_labels))  # [0, 1, 2, ...]\n",
    "        bars = plt.bar(x_pos, filtered_sizes, color='skyblue', edgecolor='black')\n",
    "\n",
    "        # Popisky pod osou\n",
    "        plt.xticks(ticks=x_pos, labels=[f\"Shluk {label}\" for label in filtered_labels], rotation=90)\n",
    "\n",
    "        plt.ylabel(\"Poƒçet jedinc≈Ø\")\n",
    "        plt.title(f\"Histogram velikost√≠ shluk≈Ø - generace {gen}\")\n",
    "        plt.grid(True, axis='y')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Ulo≈æen√≠\n",
    "        hist_path = os.path.join(images_dir, f\"histogram_gen_{gen:03d}.png\")\n",
    "        plt.savefig(hist_path)\n",
    "        plt.close()\n",
    "\n",
    "        # P≈ôid√°n√≠ do HTML\n",
    "        html_parts.append(f\"<img src='images/{os.path.basename(hist_path)}' width='600'><br>\")\n",
    "\n",
    "\n",
    "        # === Anal√Ωza stability cluster≈Ø mezi generacemi ===\n",
    "        if gen_ind > 0 and evol_name != \"GA\":\n",
    "            previous_gen = selected_generations[gen_ind - 1]\n",
    "            current_gen = gen\n",
    "\n",
    "            cluster_transitions = defaultdict(lambda: defaultdict(int))  # prev_cluster -> current_cluster -> count\n",
    "\n",
    "            for ident, history in id_cluster_map.items():\n",
    "                if len(history) > gen_ind:\n",
    "                    prev_label = history[gen_ind - 1]\n",
    "                    curr_label = history[gen_ind]\n",
    "                    cluster_transitions[prev_label][curr_label] += 1\n",
    "\n",
    "            html_parts.append(f\"<h3>Stabilita mezi generac√≠ {previous_gen} ‚Üí {current_gen}:</h3>\")\n",
    "            html_parts.append(\"<pre>\")\n",
    "            for prev_label, curr_counts in cluster_transitions.items():\n",
    "                total = sum(curr_counts.values())\n",
    "                for curr_label, count in curr_counts.items():\n",
    "                    percent = count / total * 100 if total > 0 else 0\n",
    "                    html_parts.append(f\"  Shluk {prev_label} ‚Üí {curr_label}: {count} jedinc≈Ø ({percent:.1f} %)\")\n",
    "            html_parts.append(\"</pre>\")\n",
    "\n",
    "        # === Mapov√°n√≠ pomoc√≠ Jaccardova indexu mezi p≈ôedchoz√≠ a aktu√°ln√≠ generac√≠ ===\n",
    "        if gen_ind > 0 and evol_name != \"GA\":\n",
    "            gen_a = selected_generations[gen_ind - 1]\n",
    "            gen_b = gen\n",
    "\n",
    "            clusters_a = cluster_members_by_gen[gen_a]\n",
    "            clusters_b = cluster_members_by_gen[gen_b]\n",
    "\n",
    "            html_parts.append(f\"<h3>Jaccardovo mapov√°n√≠ a overlap: Generace {gen_a} ‚Üí {gen_b}</h3>\")\n",
    "            html_parts.append(\"<pre>\")\n",
    "\n",
    "            for ca, members_a in clusters_a.items():\n",
    "                best_jaccard = 0\n",
    "                best_cb = None\n",
    "\n",
    "                for cb, members_b in clusters_b.items():\n",
    "                    intersection = len(members_a & members_b)\n",
    "                    union = len(members_a | members_b)\n",
    "                    jaccard = intersection / union if union > 0 else 0\n",
    "                    overlap = len(members_a & members_b) / min(len(members_a), len(members_b))\n",
    "\n",
    "                    if jaccard > best_jaccard:\n",
    "                        best_jaccard = jaccard\n",
    "                        best_cb = cb\n",
    "\n",
    "                if best_cb is not None:\n",
    "                    intersection = len(members_a & clusters_b[best_cb])\n",
    "                    denom = min(len(members_a), len(clusters_b[best_cb]))\n",
    "                    overlap = intersection / denom if denom > 0 else 0\n",
    "                    html_parts.append(f\" - Shluk {ca} ‚Üí {best_cb} (Jaccard: {best_jaccard:.2f}, Overlap: {overlap:.2f})\")\n",
    "                else:\n",
    "                    html_parts.append(f\" - Shluk {ca} ‚Üí ≈æ√°dn√Ω vhodn√Ω p≈ôechod\")\n",
    "\n",
    "            html_parts.append(\"</pre>\")\n",
    "        \n",
    "         # === Posun centroid≈Ø mezi p≈ôedchoz√≠ a aktu√°ln√≠ generac√≠ ===\n",
    "        if gen_ind > 0:\n",
    "            html_parts.append(f\"<h4>Posun centroid≈Ø mezi generac√≠ {selected_generations[gen_ind - 1]} ‚Üí {gen}:</h4>\")\n",
    "            html_parts.append(\"<pre>\")\n",
    "            centroids_a = centroid_history[gen_ind - 1]\n",
    "            centroids_b = centroid_history[gen_ind]\n",
    "            for j in range(min(len(centroids_a), len(centroids_b))):\n",
    "                dist = np.linalg.norm(centroids_a[j] - centroids_b[j])\n",
    "                html_parts.append(f\" - Shluk {j}: {dist:.4f}\")\n",
    "            html_parts.append(\"</pre>\")\n",
    "\n",
    "        #switch_counts = {}\n",
    "        #for ident, history in id_cluster_map.items():\n",
    "        #    switches = sum(1 for a, b in zip(history, history[1:]) if a != b)\n",
    "        #    switch_counts[ident] = switches\n",
    "\n",
    "        #total = len(switch_counts)\n",
    "        #same = sum(1 for s in switch_counts.values() if s == 0)\n",
    "        #once = sum(1 for s in switch_counts.values() if s == 1)\n",
    "        #many = sum(1 for s in switch_counts.values() if s > 1)\n",
    "\n",
    "        #print(\"Statistiky pohybu mezi clustery:\")\n",
    "        #print(f\"Celkem jedinc≈Ø: {total}\")\n",
    "        #print(f\"Z≈Østali ve stejn√©m clusteru: {same} ({same/total*100:.1f} %)\")\n",
    "        #print(f\"Zmƒõnili cluster jednou: {once} ({once/total*100:.1f} %)\")\n",
    "        #print(f\"Zmƒõnili cluster v√≠cekr√°t: {many} ({many/total*100:.1f} %)\")\n",
    "\n",
    "        # === Boxplot fitness hodnot v jednotliv√Ωch clusterech ===\n",
    "        gen_data = df[df[\"generation\"] == gen]\n",
    "        pop_values = gen_data.drop(columns=[\"generation\", \"id\"]).values\n",
    "        fitness_values = np.array([fintess_method(ind) for ind in pop_values])\n",
    "\n",
    "        # Z√≠sk√°n√≠ unik√°tn√≠ch cluster ID (vynech√°me -1 = noise)\n",
    "        cluster_ids = sorted(set(clusters) - {-1})\n",
    "\n",
    "        # Inicializace slovn√≠ku\n",
    "        cluster_fitness = {cl: [] for cl in cluster_ids}\n",
    "\n",
    "        # Naplnƒõn√≠ fitness hodnot do jednotliv√Ωch cluster≈Ø\n",
    "        for i, cl in enumerate(clusters):\n",
    "            if cl in cluster_fitness:\n",
    "                cluster_fitness[cl].append(fitness_values[i])\n",
    "\n",
    "        # Vykreslen√≠ boxplotu\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.boxplot([cluster_fitness[cl] for cl in cluster_ids],\n",
    "                    labels=[f\"Shluk {cl}\" for cl in cluster_ids])\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel(\"Shluk\")\n",
    "        plt.ylabel(\"Fitness\")\n",
    "        plt.title(f\"Distribuce fitness hodnot ‚Äì generace {gen}\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        box_path = os.path.join(images_dir, f\"boxplot_gen_{gen:03d}.png\")\n",
    "        plt.savefig(box_path)\n",
    "        plt.close()\n",
    "        html_parts.append(f\"<img src='images/{os.path.basename(box_path)}' width='600'><br>\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(selected_generations, cluster_counts, marker='o')\n",
    "    plt.xlabel(\"Generace\")\n",
    "    plt.ylabel(\"Poƒçet shluk≈Ø\")\n",
    "    plt.title(\"V√Ωvoj poƒçtu shluk≈Ø v ƒçase\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    time_cluster_path = os.path.join(images_dir, f\"time_cluster_gen_{gen:03d}.png\")\n",
    "    plt.savefig(time_cluster_path)\n",
    "    plt.close()\n",
    "    html_parts.append(f\"<img src='images/{os.path.basename(time_cluster_path)}' width='600'><br>\")\n",
    "\n",
    "    #max_cluster_id = max(len(sizes) for sizes in cluster_size_history)\n",
    "    #cluster_size_array = np.zeros((len(cluster_size_history), max_cluster_id))\n",
    "    #for i, sizes in enumerate(cluster_size_history):\n",
    "    #    for j, size in enumerate(sizes):\n",
    "    #        cluster_size_array[i, j] = size\n",
    "\n",
    "    #plt.figure(figsize=(12, 5))\n",
    "    #for j in range(cluster_size_array.shape[1]):\n",
    "    #    plt.plot(selected_generations, cluster_size_array[:, j], label=f\"Cluster {j - 1 if -1 in sizes else j}\")\n",
    "    #plt.xlabel(\"Generace\")\n",
    "    #plt.ylabel(\"Poƒçet jedinc≈Ø\")\n",
    "    #plt.title(\"V√Ωvoj velikosti cluster≈Ø v ƒçase\")\n",
    "    #plt.legend()\n",
    "    #plt.grid(True)\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "    # === V√Ωvoj velikosti cluster≈Ø v ƒçase (s korektn√≠m glob√°ln√≠m ID) ===\n",
    "    all_global_ids = sorted({cid for gen_map in cluster_members_by_gen.values() for cid in gen_map})\n",
    "    global_id_to_index = {cid: i for i, cid in enumerate(all_global_ids)}\n",
    "\n",
    "    cluster_size_array = np.zeros((len(selected_generations), len(all_global_ids)))\n",
    "\n",
    "    for gen_idx, gen in enumerate(selected_generations):\n",
    "        gen_clusters = cluster_members_by_gen[gen]\n",
    "        for gid, members in gen_clusters.items():\n",
    "            idx = global_id_to_index[gid]\n",
    "            cluster_size_array[gen_idx, idx] = len(members)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for j, gid in enumerate(all_global_ids):\n",
    "        plt.plot(selected_generations, cluster_size_array[:, j], label=f\"Shluk {gid}\")\n",
    "    plt.xlabel(\"Generace\")\n",
    "    plt.ylabel(\"Poƒçet jedinc≈Ø\")\n",
    "    plt.title(\"V√Ωvoj velikosti shluk≈Ø v ƒçase\")\n",
    "    #plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25),\n",
    "    #        ncol=5, fontsize=8, frameon=False)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    size_cluster_path = os.path.join(images_dir, f\"size_cluster_gen_{gen:03d}.png\")\n",
    "    plt.savefig(size_cluster_path)\n",
    "    plt.close()\n",
    "    html_parts.append(f\"<img src='images/{os.path.basename(size_cluster_path)}' width='1200'><br>\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.heatmap(cluster_size_array.T, cmap=\"viridis\", cbar_kws={\"label\": \"Poƒçet jedinc≈Ø\"})\n",
    "    plt.xlabel(\"Generace\")\n",
    "    plt.ylabel(\"Glob√°ln√≠ ID shluku\")\n",
    "    plt.title(\"Heatmapa v√Ωvoje velikosti shluk≈Ø v ƒçase\")\n",
    "    plt.tight_layout()\n",
    "    size_cluster_heatmap = os.path.join(images_dir, f\"Size_cluster_heatmap_gen_{gen:03d}.png\")\n",
    "    plt.savefig(size_cluster_heatmap)\n",
    "    plt.close()\n",
    "    html_parts.append(f\"<img src='images/{os.path.basename(size_cluster_heatmap)}' width='1200'><br>\")\n",
    "\n",
    "    num_clusters = cluster_size_array.shape[1]\n",
    "    chunk_size = 50  # uprav dle pot≈ôeby (nap≈ô. 50)\n",
    "    num_chunks = (num_clusters + chunk_size - 1) // chunk_size  # zaokrouhlen√≠ nahoru\n",
    "\n",
    "    if num_clusters > 50:\n",
    "        for i in range(num_chunks):\n",
    "            start = i * chunk_size\n",
    "            end = min(start + chunk_size, num_clusters)\n",
    "\n",
    "            # Z√≠sk√°n√≠ skuteƒçn√Ωch glob√°ln√≠ch ID pro tento chunk\n",
    "            chunk_ids = all_global_ids[start:end]\n",
    "            chunk_array = cluster_size_array[:, start:end].T  # ka≈æd√Ω ≈ô√°dek = jeden cluster\n",
    "\n",
    "            plt.figure(figsize=(14, 6))\n",
    "            sns.heatmap(chunk_array, cmap=\"viridis\", \n",
    "                        cbar_kws={\"label\": \"Poƒçet jedinc≈Ø\"},\n",
    "                        yticklabels=chunk_ids)  # spr√°vn√© ID na ose Y\n",
    "            plt.xlabel(\"Generace\")\n",
    "            plt.ylabel(\"Glob√°ln√≠ ID shluku\")\n",
    "            plt.title(f\"Heatmapa v√Ωvoje velikosti shluk≈Ø (Clustery {chunk_ids[0]}‚Äì{chunk_ids[-1]})\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            heatmap_path = os.path.join(images_dir, f\"size_cluster_heatmap_{chunk_ids[0]:03d}_{chunk_ids[-1]:03d}.png\")\n",
    "            plt.savefig(heatmap_path)\n",
    "            plt.close()\n",
    "\n",
    "            html_parts.append(f\"<img src='images/{os.path.basename(heatmap_path)}' width='1200'><br>\")\n",
    "\n",
    "\n",
    "\n",
    "    # === V√Ωvoj pr≈Ømƒõrn√© vzd√°lenosti mezi centroidy ===\n",
    "    average_intercentroid_distances = []\n",
    "    for centroids in centroid_history:\n",
    "        if len(centroids) < 2:\n",
    "            average_intercentroid_distances.append(0)\n",
    "            continue\n",
    "        dists = cdist(centroids, centroids)\n",
    "        upper_triangle = dists[np.triu_indices_from(dists, k=1)]\n",
    "        avg_dist = np.mean(upper_triangle)\n",
    "        average_intercentroid_distances.append(avg_dist)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(selected_generations, average_intercentroid_distances, marker='o', color='purple')\n",
    "    plt.xlabel(\"Generace\")\n",
    "    plt.ylabel(\"Pr≈Ømƒõrn√° vzd√°lenost mezi centroidy\")\n",
    "    plt.title(\"V√Ωvoj vzd√°lenost√≠ mezi centroidy\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    distance_centroid_path = os.path.join(images_dir, f\"distance_centroid_gen_{gen:03d}.png\")\n",
    "    plt.savefig(distance_centroid_path)\n",
    "    plt.close()\n",
    "    html_parts.append(f\"<img src='images/{os.path.basename(distance_centroid_path)}' width='600'><br>\")\n",
    "\n",
    "\n",
    "    #for i in range(len(centroid_history) - 1):\n",
    "    #    print(f\"\\nPosun centroid≈Ø mezi generac√≠ {selected_generations[i]} a {selected_generations[i+1]}:\")\n",
    "    #    for j in range(min(len(centroid_history[i]), len(centroid_history[i+1]))):\n",
    "    #        dist = np.linalg.norm(centroid_history[i][j] - centroid_history[i+1][j])\n",
    "    #        print(f\" - Cluster {j}: {dist:.4f}\")\n",
    "\n",
    "    # === V√Ωvoj WCSS ===\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(selected_generations, inertia_history, marker='o')\n",
    "    plt.xlabel(\"Generace\")\n",
    "    plt.ylabel(\"WCSS (inercie)\")\n",
    "    plt.title(\"V√Ωvoj kvality shluk≈Ø (inercie) ‚Äì Optics\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    wcss_path = os.path.join(images_dir, f\"wcss_gen_{gen:03d}.png\")\n",
    "    plt.savefig(wcss_path)\n",
    "    plt.close()\n",
    "    html_parts.append(f\"<img src='images/{os.path.basename(wcss_path)}' width='600'><br>\")\n",
    "\n",
    "    html_path = os.path.join(output_dir, \"report.html\")\n",
    "    with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(html_parts))\n",
    "\n",
    "    print(f\"‚úÖ HTML report byl ulo≈æen do: {html_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTML report byl ulo≈æen do: html_report\\DE\\sphere\\Optics\\report.html\n"
     ]
    }
   ],
   "source": [
    "run(\"population_log_DE_sphere.csv\", 4, 1, sphere, \"Optics\", \"DE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTML report byl ulo≈æen do: html_report\\DE\\schwefel\\Optics\\report.html\n"
     ]
    }
   ],
   "source": [
    "run(\"population_log_DE_schwefel.csv\", 4, 1, schwefel, \"Optics\", \"DE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTML report byl ulo≈æen do: html_report\\GA\\sphere\\Optics\\report.html\n"
     ]
    }
   ],
   "source": [
    "run(\"population_log_GA_sphere.csv\", 4, 1, sphere, \"Optics\", \"GA\", \"crossover_log_sphere.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTML report byl ulo≈æen do: html_report\\GA\\schwefel\\Optics\\report.html\n"
     ]
    }
   ],
   "source": [
    "run(\"population_log_GA_schwefel.csv\", 4, 1, schwefel, \"Optics\", \"GA\", \"crossover_log_schwefel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTML report byl ulo≈æen do: html_report\\PSO\\sphere\\Optics\\report.html\n"
     ]
    }
   ],
   "source": [
    "run(\"population_log_PSO_sphere.csv\", 4, 1, sphere, \"Optics\", \"PSO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTML report byl ulo≈æen do: html_report\\PSO\\schwefel\\Optics\\report.html\n"
     ]
    }
   ],
   "source": [
    "run(\"population_log_PSO_schwefel.csv\", 4, 1, schwefel, \"Optics\", \"PSO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def runing(dataset, min_samples, step, fintess_method, clustering_method_name, evol_name):\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "    unique_generations = sorted(df[\"generation\"].unique())\n",
    "\n",
    "    #selected_generations = [unique_generations[0]] + unique_generations[step-1::step] + [unique_generations[-1]]\n",
    "    selected_generations = list(dict.fromkeys(\n",
    "        [unique_generations[0]] + unique_generations[step-1::step] + [unique_generations[-1]]\n",
    "    ))\n",
    "\n",
    "    first_gen_data = df[df[\"generation\"] == unique_generations[0]].drop(columns=[\"generation\", \"id\"]).values\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(first_gen_data)\n",
    "    id_cluster_map = defaultdict(list)\n",
    "    cluster_counts = []\n",
    "    cluster_size_history = []\n",
    "    inertia_history = []\n",
    "    cluster_members_by_gen = {}\n",
    "    #global_cluster_map = {}  # {generation: {local_cluster_id: global_id}}\n",
    "    #next_global_id = 0\n",
    "\n",
    "\n",
    "    #for gen in selected_generations:\n",
    "    for gen_ind, gen in enumerate(selected_generations):\n",
    "\n",
    "        pop_data = df[df[\"generation\"] == gen].drop(columns=[\"generation\", \"id\"]).values\n",
    "\n",
    "        max_distance = np.max(cdist(pop_data, pop_data))\n",
    "        eps = 0.5 * max_distance\n",
    "        #print(0.5 * max_distance)\n",
    "        #print(0.25 * max_distance)\n",
    "        #print(0.05 * max_distance)\n",
    "\n",
    "        #print(pop_data)\n",
    "\n",
    "        #clusters = custom_optics_clustering(data=pop_data, min_samples=min_samples, max_eps=eps, eps=None)\n",
    "        #print(clusters)\n",
    "\n",
    "        #clustering = OPTICS(\n",
    "        #    min_samples=min_samples,      # Minim√°ln√≠ poƒçet bod≈Ø v hust√© oblasti\n",
    "        #    max_eps=eps,     # Maxim√°ln√≠ hledan√Ω radius (np.inf = automaticky)\n",
    "        #    xi=0.001,           # Parametr pro automatickou extrakci shluk≈Ø (voliteln√©)\n",
    "        #    metric='euclidean' # Vzd√°lenostn√≠ metrika\n",
    "        #)\n",
    "        total_points = len(pop_data)\n",
    "        for ips in np.arange(0.05, 0.8, 0.05):\n",
    "            for min_samples in range(3, 7):\n",
    "                for xi in np.arange(0.01, 0.21, 0.01):\n",
    "                    clustering = OPTICS(\n",
    "                        min_samples=min_samples,\n",
    "                        max_eps=ips*max_distance,\n",
    "                        xi=xi,\n",
    "                        metric='euclidean'\n",
    "                    )\n",
    "                    clustering.fit(pop_data)\n",
    "                    if np.all(np.isinf(clustering.reachability_)):\n",
    "                        continue\n",
    "                    labels = clustering.labels_\n",
    "                    num_outliers = np.sum(labels == -1)\n",
    "                    percent_outliers = num_outliers / total_points * 100\n",
    "\n",
    "                    num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "                    if num_clusters >= 3 and percent_outliers <= 50:\n",
    "                        star = \"**\" if percent_outliers <= 25 else \"\"\n",
    "                        print(f\"{star}min_samples={min_samples}, xi={xi:.2f}, eps={ips:.2f} ‚Üí {num_clusters} cluster≈Ø, {percent_outliers:.1f}% outlier≈Ø{star}\")\n",
    "                        for cl in sorted(set(labels)):\n",
    "                            if cl == -1:\n",
    "                                continue\n",
    "                            count = np.sum(labels == cl)\n",
    "                            print(f\"  - Cluster {cl}: {count} bod≈Ø\")\n",
    "                        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples=4, xi=0.07, eps=0.35 ‚Üí 3 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.08, eps=0.35 ‚Üí 3 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.09, eps=0.35 ‚Üí 3 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.10, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.11, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.12, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.13, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.14, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.15, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.16, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.17, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.18, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.19, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=4, xi=0.20, eps=0.35 ‚Üí 3 cluster≈Ø, 35.0% outlier≈Ø\n",
      "  - Cluster 0: 23 bod≈Ø\n",
      "  - Cluster 1: 33 bod≈Ø\n",
      "  - Cluster 2: 9 bod≈Ø\n",
      "\n",
      "min_samples=5, xi=0.01, eps=0.40 ‚Üí 6 cluster≈Ø, 45.0% outlier≈Ø\n",
      "  - Cluster 0: 21 bod≈Ø\n",
      "  - Cluster 1: 13 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "  - Cluster 3: 5 bod≈Ø\n",
      "  - Cluster 4: 5 bod≈Ø\n",
      "  - Cluster 5: 5 bod≈Ø\n",
      "\n",
      "min_samples=5, xi=0.01, eps=0.45 ‚Üí 6 cluster≈Ø, 45.0% outlier≈Ø\n",
      "  - Cluster 0: 21 bod≈Ø\n",
      "  - Cluster 1: 13 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "  - Cluster 3: 5 bod≈Ø\n",
      "  - Cluster 4: 5 bod≈Ø\n",
      "  - Cluster 5: 5 bod≈Ø\n",
      "\n",
      "min_samples=5, xi=0.01, eps=0.50 ‚Üí 6 cluster≈Ø, 45.0% outlier≈Ø\n",
      "  - Cluster 0: 21 bod≈Ø\n",
      "  - Cluster 1: 13 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "  - Cluster 3: 5 bod≈Ø\n",
      "  - Cluster 4: 5 bod≈Ø\n",
      "  - Cluster 5: 5 bod≈Ø\n",
      "\n",
      "min_samples=5, xi=0.01, eps=0.55 ‚Üí 6 cluster≈Ø, 45.0% outlier≈Ø\n",
      "  - Cluster 0: 21 bod≈Ø\n",
      "  - Cluster 1: 13 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "  - Cluster 3: 5 bod≈Ø\n",
      "  - Cluster 4: 5 bod≈Ø\n",
      "  - Cluster 5: 5 bod≈Ø\n",
      "\n",
      "min_samples=5, xi=0.01, eps=0.60 ‚Üí 6 cluster≈Ø, 45.0% outlier≈Ø\n",
      "  - Cluster 0: 21 bod≈Ø\n",
      "  - Cluster 1: 13 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "  - Cluster 3: 5 bod≈Ø\n",
      "  - Cluster 4: 5 bod≈Ø\n",
      "  - Cluster 5: 5 bod≈Ø\n",
      "\n",
      "min_samples=5, xi=0.01, eps=0.65 ‚Üí 6 cluster≈Ø, 45.0% outlier≈Ø\n",
      "  - Cluster 0: 21 bod≈Ø\n",
      "  - Cluster 1: 13 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "  - Cluster 3: 5 bod≈Ø\n",
      "  - Cluster 4: 5 bod≈Ø\n",
      "  - Cluster 5: 5 bod≈Ø\n",
      "\n",
      "min_samples=5, xi=0.01, eps=0.70 ‚Üí 6 cluster≈Ø, 45.0% outlier≈Ø\n",
      "  - Cluster 0: 21 bod≈Ø\n",
      "  - Cluster 1: 13 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "  - Cluster 3: 5 bod≈Ø\n",
      "  - Cluster 4: 5 bod≈Ø\n",
      "  - Cluster 5: 5 bod≈Ø\n",
      "\n",
      "min_samples=5, xi=0.01, eps=0.75 ‚Üí 6 cluster≈Ø, 45.0% outlier≈Ø\n",
      "  - Cluster 0: 21 bod≈Ø\n",
      "  - Cluster 1: 13 bod≈Ø\n",
      "  - Cluster 2: 6 bod≈Ø\n",
      "  - Cluster 3: 5 bod≈Ø\n",
      "  - Cluster 4: 5 bod≈Ø\n",
      "  - Cluster 5: 5 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.10, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.11, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.12, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.13, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.14, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.15, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.16, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.17, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.18, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.19, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.20, eps=0.30 ‚Üí 4 cluster≈Ø, 38.0% outlier≈Ø\n",
      "  - Cluster 0: 51 bod≈Ø\n",
      "  - Cluster 1: 4 bod≈Ø\n",
      "  - Cluster 2: 4 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.35 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.40 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.45 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.50 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.55 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.60 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.65 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.70 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n",
      "min_samples=3, xi=0.01, eps=0.75 ‚Üí 10 cluster≈Ø, 49.0% outlier≈Ø\n",
      "  - Cluster 0: 11 bod≈Ø\n",
      "  - Cluster 1: 3 bod≈Ø\n",
      "  - Cluster 2: 12 bod≈Ø\n",
      "  - Cluster 3: 3 bod≈Ø\n",
      "  - Cluster 4: 3 bod≈Ø\n",
      "  - Cluster 5: 4 bod≈Ø\n",
      "  - Cluster 6: 4 bod≈Ø\n",
      "  - Cluster 7: 5 bod≈Ø\n",
      "  - Cluster 8: 3 bod≈Ø\n",
      "  - Cluster 9: 3 bod≈Ø\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runing(\"population_log_DE_sphere.csv\", 3, 10, sphere, \"Optics\", \"DE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
